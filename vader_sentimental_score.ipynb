{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b7a79a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\TAMILSELVAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  mean_title_sentiment  mean_description_sentiment  \\\n",
      "0   2024-07-09             -0.019346                    0.092961   \n",
      "1   2024-07-10              0.035975                    0.175266   \n",
      "2   2024-07-11             -0.102986                    0.073126   \n",
      "3   2024-07-12              0.012971                    0.116878   \n",
      "4   2024-07-13             -0.022923                    0.051927   \n",
      "5   2024-07-14              0.028743                    0.189363   \n",
      "6   2024-07-15             -0.032253                    0.125018   \n",
      "7   2024-07-16             -0.002119                    0.116483   \n",
      "8   2024-07-17             -0.029091                    0.106871   \n",
      "9   2024-07-18              0.001090                    0.106564   \n",
      "10  2024-07-19              0.026746                    0.160584   \n",
      "11  2024-07-20             -0.110624                    0.019728   \n",
      "12  2024-07-21              0.019517                    0.115370   \n",
      "13  2024-07-22              0.020059                    0.116930   \n",
      "14  2024-07-23             -0.004241                    0.114565   \n",
      "15  2024-07-24              0.025029                    0.158892   \n",
      "16  2024-07-25             -0.049734                    0.066341   \n",
      "17  2024-07-26              0.011867                    0.030357   \n",
      "18  2024-07-27             -0.054830                    0.039649   \n",
      "19  2024-07-28              0.045492                    0.050066   \n",
      "20  2024-07-29             -0.023891                    0.057149   \n",
      "21  2024-07-30             -0.035898                    0.127338   \n",
      "22  2024-07-31              0.036955                    0.175823   \n",
      "23  2024-08-01              0.031121                    0.218641   \n",
      "24  2024-08-02             -0.027982                    0.205754   \n",
      "25  2024-08-03             -0.079191                    0.005766   \n",
      "26  2024-08-04             -0.099167                    0.025323   \n",
      "27  2024-08-05             -0.046302                   -0.000366   \n",
      "28  2024-08-06              0.048172                    0.096537   \n",
      "29  2024-08-07              0.011887                    0.085471   \n",
      "30  2024-08-08              0.006834                    0.212220   \n",
      "\n",
      "    mean_content_sentiment  \n",
      "0                 0.124143  \n",
      "1                 0.198074  \n",
      "2                 0.057802  \n",
      "3                 0.191816  \n",
      "4                 0.096161  \n",
      "5                 0.167418  \n",
      "6                 0.145965  \n",
      "7                 0.133726  \n",
      "8                 0.152383  \n",
      "9                 0.103828  \n",
      "10                0.103107  \n",
      "11                0.020445  \n",
      "12                0.109177  \n",
      "13                0.100386  \n",
      "14                0.133668  \n",
      "15                0.181820  \n",
      "16                0.109576  \n",
      "17                0.054377  \n",
      "18                0.075670  \n",
      "19                0.140124  \n",
      "20                0.107909  \n",
      "21                0.119083  \n",
      "22                0.181771  \n",
      "23                0.237817  \n",
      "24                0.183474  \n",
      "25                0.027462  \n",
      "26                0.039914  \n",
      "27                0.000120  \n",
      "28                0.142839  \n",
      "29                0.164171  \n",
      "30                0.166642  \n",
      "Error fetching article content from https://content.guardianapis.com/business/2023/nov/02/shells-moves-ahead-with-35bn-shareholder-windfall-despite-profits-fall: 429 Client Error: Too Many Requests for url: https://content.guardianapis.com/business/2023/nov/02/shells-moves-ahead-with-35bn-shareholder-windfall-despite-profits-fall?api-key=b001c2f9-9358-4483-a3bc-da632b995c95&show-fields=body,trailText\n",
      "Error fetching article content from https://content.guardianapis.com/business/2023/oct/31/bp-profits-gas-bernard-looney: 429 Client Error: Too Many Requests for url: https://content.guardianapis.com/business/2023/oct/31/bp-profits-gas-bernard-looney?api-key=b001c2f9-9358-4483-a3bc-da632b995c95&show-fields=body,trailText\n",
      "Error fetching article content from https://content.guardianapis.com/business/2023/oct/30/world-bank-warns-oil-price-could-soar-to-record-150-a-barrel: 429 Client Error: Too Many Requests for url: https://content.guardianapis.com/business/2023/oct/30/world-bank-warns-oil-price-could-soar-to-record-150-a-barrel?api-key=b001c2f9-9358-4483-a3bc-da632b995c95&show-fields=body,trailText\n",
      "Error fetching article content from https://content.guardianapis.com/us-news/2023/oct/23/louisiana-gas-export-hub-biden-climate-crisis: 429 Client Error: Too Many Requests for url: https://content.guardianapis.com/us-news/2023/oct/23/louisiana-gas-export-hub-biden-climate-crisis?api-key=b001c2f9-9358-4483-a3bc-da632b995c95&show-fields=body,trailText\n",
      "Error fetching article content from https://content.guardianapis.com/commentisfree/2023/oct/20/martin-scorsese-killers-of-the-flower-moon-osage-us-government: 429 Client Error: Too Many Requests for url: https://content.guardianapis.com/commentisfree/2023/oct/20/martin-scorsese-killers-of-the-flower-moon-osage-us-government?api-key=b001c2f9-9358-4483-a3bc-da632b995c95&show-fields=body,trailText\n",
      "           date  title_sentiment  description_sentiment  content_sentiment  \\\n",
      "0    2023-10-19         -0.25000                0.28080            0.96040   \n",
      "1    2023-10-20         -0.72565               -0.14800            0.25700   \n",
      "2    2023-10-22         -0.45880                0.00000           -0.42830   \n",
      "3    2023-10-23         -0.44040               -0.29600           -0.29600   \n",
      "4    2023-10-25         -0.13660                0.38275           -0.05590   \n",
      "..          ...              ...                    ...                ...   \n",
      "139  2024-08-04              NaN                    NaN                NaN   \n",
      "140  2024-08-05         -0.69080                0.02580           -0.96870   \n",
      "141  2024-08-06         -0.27530               -0.26210           -0.84325   \n",
      "142  2024-08-07              NaN                    NaN                NaN   \n",
      "143  2024-08-08              NaN                    NaN                NaN   \n",
      "\n",
      "     mean_title_sentiment  mean_description_sentiment  mean_content_sentiment  \n",
      "0                     NaN                         NaN                     NaN  \n",
      "1                     NaN                         NaN                     NaN  \n",
      "2                     NaN                         NaN                     NaN  \n",
      "3                     NaN                         NaN                     NaN  \n",
      "4                     NaN                         NaN                     NaN  \n",
      "..                    ...                         ...                     ...  \n",
      "139             -0.099167                    0.025323                0.039914  \n",
      "140             -0.046302                   -0.000366                0.000120  \n",
      "141              0.048172                    0.096537                0.142839  \n",
      "142              0.011887                    0.085471                0.164171  \n",
      "143              0.006834                    0.212220                0.166642  \n",
      "\n",
      "[144 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import concurrent.futures\n",
    "from datetime import datetime, timedelta\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mplfinance as mpf\n",
    "import nltk\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "\n",
    "API_KEY_GUARDIAN = \"b001c2f9-9358-4483-a3bc-da632b995c95\"\n",
    "NEWS_API_KEY = \"0bbb8dd5a0754e0fb14d9364e924d9e0\"\n",
    "SHELL_TICKER = 'SHEL'\n",
    "BP_TICKER = 'BP'\n",
    "\n",
    "# Initialize VADER sentiment analyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "def fetch_data_guardian(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def fetch_article_content_guardian(api_url):\n",
    "    try:\n",
    "        response = requests.get(api_url + \"?api-key=\" + API_KEY_GUARDIAN + \"&show-fields=body,trailText\")\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        content = data['response']['content']['fields'].get('body', 'No content available')\n",
    "        description = data['response']['content']['fields'].get('trailText', 'No description available')\n",
    "        return content, description\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching article content from {api_url}: {e}\")\n",
    "        return None, None\n",
    "    except KeyError as e:\n",
    "        print(f\"Error parsing article content: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def extract_info_guardian(json_data):\n",
    "    if not json_data:\n",
    "        return []\n",
    "    try:\n",
    "        articles = json_data['response']['results']\n",
    "        return [\n",
    "            {\n",
    "                'title': article['webTitle'],\n",
    "                'sectionname': article['sectionName'],\n",
    "                'publisheddate': article['webPublicationDate'],\n",
    "                'api_url': article['apiUrl']\n",
    "            } for article in articles\n",
    "        ]\n",
    "    except KeyError as e:\n",
    "        print(f\"Error parsing data: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def analyze_sentiment_vader(text):\n",
    "    vs = analyzer.polarity_scores(text)\n",
    "    return vs['compound']\n",
    "\n",
    "\n",
    "def fetch_guardian_news():\n",
    "    urllist = []\n",
    "    for i in range(1, 17):\n",
    "        base_url = \"https://content.guardianapis.com/business/oil?from-date=2023-01-01&api-key=\" + API_KEY_GUARDIAN + \"&type=article&page=\"\n",
    "        url = base_url + str(i)\n",
    "        urllist.append(url)\n",
    "\n",
    "    urls = urllist\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        json_data_list = list(executor.map(fetch_data_guardian, urls))\n",
    "    \n",
    "    info = []\n",
    "    for json_data in json_data_list:\n",
    "        info.extend(extract_info_guardian(json_data))\n",
    "    \n",
    "    if info:\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "            content_and_descriptions = list(executor.map(fetch_article_content_guardian, [article['api_url'] for article in info]))\n",
    "        \n",
    "        for i, (content, description) in enumerate(content_and_descriptions):\n",
    "            if content and description:\n",
    "                info[i]['content'] = content\n",
    "                info[i]['description'] = description\n",
    "            else:\n",
    "                info[i]['content'] = 'No content available'\n",
    "                info[i]['description'] = 'No description available'\n",
    "            info[i].pop('api_url')  # Remove api_url from the final data\n",
    "\n",
    "        df = pd.DataFrame(info)\n",
    "\n",
    "        # Perform sentiment analysis on title, description, and content\n",
    "        df['title_sentiment'] = df['title'].map(analyze_sentiment_vader)\n",
    "        df['description_sentiment'] = df['description'].map(analyze_sentiment_vader)\n",
    "        df['content_sentiment'] = df['content'].map(analyze_sentiment_vader)\n",
    "        \n",
    "        # Convert publisheddate to datetime format and then to date\n",
    "        df['publisheddate'] = pd.to_datetime(df['publisheddate']).dt.date\n",
    "        \n",
    "        # Select only numeric columns for grouping\n",
    "        sentiment_columns = ['title_sentiment', 'description_sentiment', 'content_sentiment']\n",
    "        \n",
    "        # Group by date and calculate the mean of sentiment scores\n",
    "        sentiment_df = df.groupby('publisheddate')[sentiment_columns].mean().reset_index()\n",
    "\n",
    "        # Rename 'publisheddate' to 'date'\n",
    "        sentiment_df.rename(columns={'publisheddate': 'date'}, inplace=True)\n",
    "\n",
    "        # Save the sentiment analysis DataFrame to a CSV file\n",
    "        sentiment_df.to_csv('guardian_oil_articles_vader_sentiment.csv', index=False)\n",
    "\n",
    "        return sentiment_df\n",
    "    else:\n",
    "        print(\"No data found\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def fetch_news_for_date(api_key, query, date):\n",
    "    url = (f\"https://newsapi.org/v2/everything?\"\n",
    "           f\"q={query}&from={date}&to={date}&\"\n",
    "           f\"sortBy=publishedAt&apiKey={api_key}&pageSize=100&page=1\")\n",
    "    response = requests.get(url)\n",
    "    return response.json()\n",
    "\n",
    "def preprocess_news(articles):\n",
    "    news_df = pd.DataFrame(articles)\n",
    "    news_df['publishedAt'] = pd.to_datetime(news_df['publishedAt'])\n",
    "    news_df = news_df.drop_duplicates(subset='url')\n",
    "    news_df = news_df[['publishedAt', 'title', 'description', 'content', 'url']]\n",
    "    news_df = news_df.dropna(subset=['title', 'description', 'content'])\n",
    "    return news_df\n",
    "\n",
    "def fetch_and_aggregate_sentiment(api_key, query, start_date, end_date):\n",
    "    current_date = start_date\n",
    "    all_aggregate_sentiments = []\n",
    "\n",
    "    while current_date <= end_date:\n",
    "        news_data = fetch_news_for_date(api_key, query, current_date.strftime('%Y-%m-%d'))\n",
    "        \n",
    "        if 'articles' in news_data:\n",
    "            articles = news_data['articles']\n",
    "            news_df = preprocess_news(articles)\n",
    "            \n",
    "            if not news_df.empty:\n",
    "                news_df['title_sentiment'] = news_df['title'].apply(analyze_sentiment_vader)\n",
    "                news_df['description_sentiment'] = news_df['description'].apply(analyze_sentiment_vader)\n",
    "                news_df['content_sentiment'] = news_df['content'].apply(analyze_sentiment_vader)\n",
    "\n",
    "                aggregate_sentiment = {\n",
    "                    'date': current_date.strftime('%Y-%m-%d'),\n",
    "                    'mean_title_sentiment': news_df['title_sentiment'].mean(),\n",
    "                    'mean_description_sentiment': news_df['description_sentiment'].mean(),\n",
    "                    'mean_content_sentiment': news_df['content_sentiment'].mean()\n",
    "                }\n",
    "            else:\n",
    "                aggregate_sentiment = {\n",
    "                    'date': current_date.strftime('%Y-%m-%d'),\n",
    "                    'mean_title_sentiment': None,\n",
    "                    'mean_description_sentiment': None,\n",
    "                    'mean_content_sentiment': None\n",
    "                }\n",
    "        else:\n",
    "            print(f\"No articles found for {current_date.strftime('%Y-%m-%d')} or API error.\")\n",
    "            aggregate_sentiment = {\n",
    "                'date': current_date.strftime('%Y-%m-%d'),\n",
    "                'mean_title_sentiment': None,\n",
    "                'mean_description_sentiment': None,\n",
    "                'mean_content_sentiment': None\n",
    "            }\n",
    "        \n",
    "        all_aggregate_sentiments.append(aggregate_sentiment)\n",
    "        current_date += timedelta(days=1)\n",
    "\n",
    "    return pd.DataFrame(all_aggregate_sentiments)\n",
    "\n",
    "# Fetch news data and aggregate sentiment scores for the specified date range\n",
    "news_query = 'oil'\n",
    "news_start_date = datetime.strptime('2024-07-09', '%Y-%m-%d')\n",
    "news_end_date = datetime.strptime('2024-08-08', '%Y-%m-%d')\n",
    "\n",
    "news_sentiments_df = fetch_and_aggregate_sentiment(NEWS_API_KEY, news_query, news_start_date, news_end_date)\n",
    "\n",
    "# Ensure 'date' is in date format\n",
    "news_sentiments_df['date'] = pd.to_datetime(news_sentiments_df['date']).dt.date\n",
    "\n",
    "# Group by date and calculate the mean of sentiment scores where dates overlap\n",
    "news_sentiments_df = news_sentiments_df.groupby('date').mean().reset_index()\n",
    "\n",
    "# Save the aggregated sentiment DataFrame to a CSV file\n",
    "news_sentiments_df.to_csv('news_vader_sentiment.csv', index=False)\n",
    "\n",
    "# Display the aggregated sentiment DataFrame\n",
    "print(news_sentiments_df)\n",
    "\n",
    "\n",
    "# Fetch Guardian news sentiments\n",
    "guardian_sentiments_df = fetch_guardian_news()\n",
    "\n",
    "# Combine both DataFrames\n",
    "combined_sentiments_df = pd.concat([guardian_sentiments_df, news_sentiments_df])\n",
    "\n",
    "# Group by date and calculate the mean of sentiment scores\n",
    "combined_sentiments_df = combined_sentiments_df.groupby('date').mean().reset_index()\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "combined_sentiments_df.to_csv('combined_vader_sentiment.csv', index=False)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(combined_sentiments_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9a4ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
